{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                    Machine Learning with Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMBALANCED DATASET - The dataset may contain uneven samples /instances , so that it makes the algorithm to predict with accuracy of 1.0 each time u run the model. For example, if u have simple dataset with 4 features and output(target) feature with 2 class, then total no. of instances/samples be 100. Now, out of 100, 80 instances belongs to category1 of the output(target) feature and only 20 instances contribute to the category2 of the output(target) feature. So, obviously, this makes bias in training and predicting the model. So, this dataset refers to Imbalanced dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Neccessary Packages and reading the csv file and printing the head of the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mcg   Gvh   Lip  Chg   Aac  Alm1  Alm2     Class\n",
      "0  0.49  0.29  0.48  0.5  0.56  0.24  0.35  positive\n",
      "1  0.07  0.40  0.48  0.5  0.54  0.35  0.44  positive\n",
      "2  0.56  0.40  0.48  0.5  0.49  0.37  0.46  positive\n",
      "3  0.59  0.49  0.48  0.5  0.52  0.45  0.36  positive\n",
      "4  0.23  0.32  0.48  0.5  0.55  0.25  0.35  positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file = pd.read_csv(\"ecoli.csv\")\n",
    "print(file.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking whether any column in the dataset contains NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the Basic Statistics(Descriptive) of the \"Class\" feature in the dataset. It shows that there are two unique values(positive and negative), with positive value counts upto 143 and negative 77."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    220.000000\n",
       "mean       0.650000\n",
       "std        0.478057\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['Class'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just grouped the datset based on the 'class' feature to visualize the counts of positive and negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mcg</th>\n",
       "      <th>Gvh</th>\n",
       "      <th>Lip</th>\n",
       "      <th>Chg</th>\n",
       "      <th>Aac</th>\n",
       "      <th>Alm1</th>\n",
       "      <th>Alm2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mcg  Gvh  Lip  Chg  Aac  Alm1  Alm2\n",
       "Class                                        \n",
       "negative   77   77   77   77   77    77    77\n",
       "positive  143  143  143  143  143   143   143"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = file.groupby(\"Class\")\n",
    "f.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are converting the 'class' feature from text to int using .map function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "file['Class'] = file['Class'].map({'positive': 1, 'negative': 0})\n",
    "print(file['Class'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the sklearn library, we import train_test_test from cross validation and split the original dataset into training and test dataset(80,20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 8)\n",
      "(44, 8)\n",
      "(176, 7)\n",
      "(44, 7)\n",
      "(176,)\n",
      "(44,)\n",
      "65     1\n",
      "33     1\n",
      "121    1\n",
      "172    0\n",
      "197    0\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train, test = train_test_split(file,test_size=0.2)\n",
    "features_train=train[['Mcg','Gvh','Lip','Chg','Aac','Alm1','Alm2']]\n",
    "features_test = test[['Mcg','Gvh','Lip','Chg','Aac','Alm1','Alm2']]\n",
    "labels_train = train.Class\n",
    "labels_test = test.Class\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(labels_train.shape)\n",
    "print(labels_test.shape)\n",
    "print(labels_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the RandomForest Classifier we can select the most important features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mcg', 0.20951777384428608)\n",
      "('Gvh', 0.20707346208561445)\n",
      "('Lip', 0.012441702752942896)\n",
      "('Chg', 0.0)\n",
      "('Aac', 0.27706112782727904)\n",
      "('Alm1', 0.15604494684526365)\n",
      "('Alm2', 0.13786098664461391)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "model = clf.fit(features_train, labels_train)\n",
    "feature_labels = ['Mcg','Gvh','Lip','Chg','Aac','Alm1','Alm2']\n",
    "for feature in zip(feature_labels,model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the feature 'Chg' is contributing very low. So we can slice the dataset with only limited features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mcg</th>\n",
       "      <th>Gvh</th>\n",
       "      <th>Lip</th>\n",
       "      <th>Aac</th>\n",
       "      <th>Alm1</th>\n",
       "      <th>Alm2</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mcg   Gvh   Lip   Aac  Alm1  Alm2  Class\n",
       "0  0.49  0.29  0.48  0.56  0.24  0.35      1\n",
       "1  0.07  0.40  0.48  0.54  0.35  0.44      1\n",
       "2  0.56  0.40  0.48  0.49  0.37  0.46      1\n",
       "3  0.59  0.49  0.48  0.52  0.45  0.36      1\n",
       "4  0.23  0.32  0.48  0.55  0.25  0.35      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_file = file[['Mcg','Gvh','Lip','Aac','Alm1','Alm2','Class']]\n",
    "new_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now once again, using the sklearn library, we import train_test_test from cross validation and split the new sliced dataset into training and test dataset(80,20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 7)\n",
      "(44, 7)\n",
      "(176, 6)\n",
      "(44, 6)\n",
      "(176,)\n",
      "(44,)\n",
      "144    0\n",
      "53     1\n",
      "69     1\n",
      "67     1\n",
      "38     1\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(new_file,test_size=0.2)\n",
    "new_features_train=train[['Mcg','Gvh','Lip','Aac','Alm1','Alm2']]\n",
    "new_features_test = test[['Mcg','Gvh','Lip','Aac','Alm1','Alm2']]\n",
    "labels_train = train.Class\n",
    "labels_test = test.Class\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(new_features_train.shape)\n",
    "print(new_features_test.shape)\n",
    "print(labels_train.shape)\n",
    "print(labels_test.shape)\n",
    "print(labels_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using Random forest Classifier and Logistic Regression we calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Randomforest Classifier: 0.977272727273\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "model = clf.fit(new_features_train, labels_train)\n",
    "print(\"Accuracy of Randomforest Classifier:\",clf.score(new_features_test,labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.977272727273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(new_features_train, labels_train)\n",
    "print('Accuracy:',clf.score(new_features_test,labels_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, both the classifiers accuracy points to 97%, which is biased due to the fact that there are 143 POSITIVE classes and 77 NEGATIVE classes. So this creates the biased results. So, this is a Imbalanced DataSet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There two main ways to handle the Imbalanced datset:\n",
    "\n",
    "1.Over Sampling  \n",
    "\n",
    "2.Under Sampling  \n",
    "\n",
    "OVER SAMPLING:  \n",
    "\n",
    "It is nothing but Sampling the minority class and making it equivalent to the majority class Ex:before sampling: Counter({1: 111, 0: 65}) after sampling: Counter({1: 111, 0: 111}) Note:The counts of 1's and 0's before and after sampling\n",
    "\n",
    "UNDER SAMPLING:  \n",
    "\n",
    "It is nothing but Sampling the majority class and making it equivalent to the minority class Ex:before sampling: Counter({1: 111, 0: 65}) after sampling: Counter({0: 65, 1: 65})\n",
    "\n",
    "There are several algorithms for over sampling and under sampling. The one we use here is,  \n",
    "\n",
    "OVER SAMPLING ALGORITHM:  \n",
    "\n",
    "1.SMOTE - Synthetic Minority Over Sampling Technique A subset of data is taken from the minority class as an example and then new synthetic similar instances are created. These synthetic instances are then added to the original dataset. The new dataset is used as a sample to train the classification models\n",
    "\n",
    "UNDER SAMPLING ALGORITHM:  \n",
    "\n",
    "1.RandomUnderSampler - Random Undersampling aims to balance class distribution by randomly eliminating majority class examples. This is done until the majority and minority class instances are balanced out.\n",
    "\n",
    "2.NearMiss - selects the majority class samples whose average distances to three closest minority class samples are the smallest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before sampling: Counter({1: 115, 0: 61})\n",
      "after sampling: Counter({1: 115, 0: 115})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled, y_resampled = SMOTE(kind='borderline1').fit_sample(new_features_train, labels_train)\n",
    "print(\"before sampling:\",format(Counter(labels_train)))\n",
    "print(\"after sampling:\",format(Counter(y_resampled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see that, the accuracy of both the classifiers drops down to 95% which the correct accuracy for this imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.954545454545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "print('Accuracy:',clf.score(new_features_test,labels_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Randomforest Classifier: 0.954545454545\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "model = clf.fit(X_resampled, y_resampled)\n",
    "print(\"Accuracy of Randomforest Classifier:\",clf.score(new_features_test,labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
